# 2.3 Structured Output (Schemas)

### Introduction
The biggest hurdle in moving from a "demo" to a "product" is parsing the LLM's response. LangChain's integration with Pydantic ensures that the model always speaks in a way your code can understand.

### Objective
Learn how to define schemas using Pydantic and force the LLM to return valid Python objects every time.

### Concept
Structured output works by:
1. **Schema Definition:** Defining expected fields and types (string, int, list).
2. **Model Binding:** Telling the LLM to use this schema (often using OpenAI's "Functions" or "JSON Mode" internally).
3. **Validation:** Pydantic automatically validates the LLM's response before it ever reaches your application logic.

### Example
```python
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI

class RAGResponse(BaseModel):
    answer: str = Field(description="The final answer to the user")
    source_id: int = Field(description="The ID of the document used to answer")
    confidence: float = Field(description="Score from 0 to 1")

model = ChatOpenAI(model="gpt-4o")
# The modern way to handle structures
structured_llm = model.with_structured_output(RAGResponse)

result = structured_llm.invoke("Based on doc 42, the price is $10.")
print(result.answer)    # "The price is $10."
print(result.source_id) # 42
```

### 2 Use Cases
1. **RAG Citations:** Forcing the LLM to return not just an answer, but a structured list of which PDF page numbers it used.
2. **Intent Classification:** Converting a user's chat message into a standardized JSON intent like `{"type": "billing", "urgency": "high"}`.

### Real-World RAG & Agentic Context
In **Real-World RAG**, structured output is used for **"Auto-Refinement"**. If the LLM returns `confidence: 0.2`, your code can automatically trigger a "Fallback" search or ask the user to clarify, preventing bad information from being presented as fact.
In **Agentic Systems**, structured output IS **"Tool Calling"**. When an agent decides to use a tool (e.g., `Search_Database`), it MUST generate a JSON object that matches the database's API. Without structured output, agents are just "hallucinating scripts"; with it, they are "executing reliable code".

### Did you know?
Most modern LLMs have been specifically trained on billions of lines of code to be excellent at following JSON schemas. However, "Small models" (SLMs) often struggle with this. If you are using a local 7B model, you might need extra "Output Correction" chains to fix its broken JSON.
