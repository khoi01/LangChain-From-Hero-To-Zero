# 2.2 Prompt Engineering with Templates

### Introduction
Prompt engineering in production is about **repeatable structures**. LangChain's `ChatPromptTemplate` allows you to separate the code (logic) from the prose (prompts).

### Objective
Learn how to build dynamic, multi-role prompts that can safely inject data from external sources like vector databases.

### Concept
A production-grade prompt template usually includes:
- **Instructions:** How the model should behave.
- **Few-Shot Examples:** (Optional) Examples of correct input/output.
- **Context Placeholders:** Where the retrieved RAG data will go.
- **User Input:** The final query.

### Example
```python
from langchain_core.prompts import ChatPromptTemplate

# A typical RAG prompt template
rag_template = ChatPromptTemplate.from_messages([
    ("system", "You are a factual assistant. Answer the user question ONLY using the provided context. If the answer isn't in the context, say 'I don't know'."),
    ("user", "Context: {context}\n\nQuestion: {question}")
])

# Variables can be injected during runtime
final_prompt = rag_template.invoke({
    "context": "The company was founded in 1995.",
    "question": "When was the company founded?"
})
```

### 2 Use Cases
1. **Dynamic RAG Context Injection:** Inserting snippets from a PDF directly into a pre-defined instruction set.
2. **Standardized Brand Voice:** Ensuring every customer response starts with "Hello, thank you for contacting us" and follows a specific brand tone.

### Real-World RAG & Agentic Context
In **Real-World RAG**, prompt templates are where you implement **"Context Grounding"**. By strictly instructing the model to *only* use the `{context}` variable, you significantly reduce hallucinations. This is the #1 technique for building trustworthy RAG.
In **Agentic Systems**, templates are used for **"Persona Engineering"**. An agent might have a "Planning Template" for breaking down tasks and a "Review Template" for checking tool outputs. Templates allow you to manage these distinct "agent behaviors" without hardcoding strings across your application.

### Did you know?
You can store your prompt templates in **LangSmith Prompt Hub**. Instead of editing Python files to improve a prompt, you can edit it in a web UI, version it, and pull the latest version directly into your code. This allows non-developers (like product managers) to optimize prompts safely.
