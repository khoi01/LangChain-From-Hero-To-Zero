{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b0e5f79-acde-4a51-a5b5-d92ab38697db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f22836-593b-4dd4-8f72-19eba37e79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae35557c-39f9-43dc-91d9-a91c45f61703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG (Retrieval-Augmented Generation) is a framework that combines retrieval-based methods with generative models to enhance the capabilities of AI systems, particularly in natural language processing tasks. The key components of Agentic RAG typically include:\n",
      "\n",
      "1. **Retrieval Mechanism**: This component is responsible for fetching relevant information from a large corpus or database. It can use various techniques, such as keyword matching, semantic search, or more advanced methods like dense retrieval using embeddings.\n",
      "\n",
      "2. **Generative Model**: This is usually a transformer-based model (like GPT or BERT) that generates text based on the input it receives. The generative model takes the retrieved information and combines it with the input query to produce coherent and contextually relevant responses.\n",
      "\n",
      "3. **Agentic Behavior**: This refers to the system's ability to act autonomously and make decisions based on the retrieved information. It involves understanding user intent, context, and the ability to adapt responses based on the situation.\n",
      "\n",
      "4. **Contextual Understanding**: The system should be able to maintain context over a conversation or interaction, allowing it to provide more relevant and personalized responses.\n",
      "\n",
      "5. **Feedback Loop**: Incorporating user feedback to improve the retrieval and generation processes over time. This can involve reinforcement learning or other methods to refine the model's performance based on real-world interactions.\n",
      "\n",
      "6. **Integration Layer**: This component ensures seamless communication between the retrieval and generative components, allowing for efficient data flow and processing.\n",
      "\n",
      "7. **User Interface**: The front-end through which users interact with the system, which can include chat interfaces, APIs, or other means of communication.\n",
      "\n",
      "8. **Evaluation Metrics**: Tools and methods to assess the performance of the Agentic RAG system, ensuring that it meets desired standards for accuracy, relevance, and user satisfaction.\n",
      "\n",
      "These components work together to create a system that can effectively retrieve relevant information and generate meaningful responses, enhancing the overall user experience in various applications, such as chatbots, virtual assistants, and information retrieval systems.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"what are the key component of Agentic RAG?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7a81b5-6da7-496a-85a2-81d9c1c526b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in October 2021, the mayor of Ipoh City Council was Datuk Rumaizi Baharin. However, please verify this information from a current and reliable source, as there may have been changes or new appointments since then.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"mayor for Ipoh City Council?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974740c-7bcf-4685-8785-77330c567820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
