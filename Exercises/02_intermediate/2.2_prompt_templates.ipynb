{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4a78d-723d-499d-a464-b2cc8ebe7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Typical RAG prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4dc765-d305-4a10-a9aa-e8e631cf7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Case 1: Real-World RAG (Context Grounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2d872-58af-4b2d-acdc-8f8797ca2f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees are entitled to 20 days of annual leave.\n"
     ]
    }
   ],
   "source": [
    " \n",
    " from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. RAG prompt template (unchanged logic, cleaned formatting)\n",
    "rag_template = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"You are a Legal Assistant.\n",
    "Use the provided DOCUMENT CONTEXT to answer the question.\n",
    "If the answer is not in the context, say \"I cannot find this in our database.\"\n",
    "Do NOT use your own knowledge.\"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"DOCUMENT CONTEXT:\\n{context}\\n\\nQUESTION: {question}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2. Simulated RAG retrieval\n",
    "context_data = \"Section 4.2: Employees are entitled to 20 days of annual leave.\"\n",
    "query = \"How much leave do I get?\"\n",
    "\n",
    "# 3. Create LLM (deterministic for legal use)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 4. apply prompt\n",
    "prompt =  rag_template.invoke({\n",
    "        \"context\": context_data,\n",
    "        \"question\": query\n",
    "    }).to_messages()\n",
    "\n",
    "# 5 Invoke prompt + LLM in ONE step\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# 5. Output\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcd91962-f36d-4d76-a7f8-786046ea8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Case 2: Agentic Persona Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17737f03-e502-4666-bed0-44d7b4990bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina won the 2022 FIFA World Cup. They defeated France in the final, which took place on December 18, 2022, in Qatar. The match ended in a dramatic penalty shootout after a 3-3 draw in regulation and extra time. This victory marked Argentina's third World Cup title, with their previous wins in 1978 and 1986.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. Agent prompt\n",
    "agent_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a Research Agent.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 2. Create LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 3. Format prompt\n",
    "prompt = agent_template.invoke(\n",
    "    {\n",
    "        \"input\": \"Who won the world cup 2022?\",\n",
    "        \"agent_scratchpad\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. Invoke LLM\n",
    "response = llm.invoke(prompt.to_messages())\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231d1c5-c4b5-4ad0-a224-84ac2415e138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
