# 3.2 Vector Stores & Retrieval

### Introduction
To build a RAG system, you need more than just a list of files; you need a way to search those files by "meaning". Vector Databases like ChromaDB turn words into geometry, where similar ideas are physically close to each other.

### Objective
Learn how to create a vector store, choose an embedding model, and turn a static database into a dynamic "Retriever".

### Concept
1. **Embedding Models:** These convert text into a list of numbers (vectors). We use `paraphrase-multilingual-MiniLM-L12-v2` for high-quality, local, and free embeddings.
2. **Dimension:** The length of the vector. More dimensions = more nuance, but slower search.
3. **Similarity Metrics:** How the DB "measures" distance. **Cosine Similarity** is the industry standard for text.

---

### Complete Implementation
Here is the full code to create a vector store and query it locally.

```python
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# 1. Setup Embedding Model
model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
embeddings = HuggingFaceEmbeddings(model_name=model_name)

# 2. Create Vector Store (From Text)
vectorstore = Chroma.from_texts(
    ["The CEO is Alice", "The office is in New York"],
    embedding=embeddings
)

# 3. Create a Retriever
# 'k=1' returns only the single most similar document
retriever = vectorstore.as_retriever(search_kwargs={"k": 1})

# 4. Execution
# The system embeds the question and finds the closest vector
docs = retriever.invoke("Who leads the company?")
print(docs[0].page_content) # Output: "The CEO is Alice"
```

---

### 2 Use Cases
1. **Semantic FAQ Bot:** Finding the answer to "How do I reset my password?" even if the user asks "I forgot my sign-in secret."
2. **Document Clustering:** Automatically grouping similar legal contracts together based on their mathematical "meaning" in the vector space.

### Real-World RAG & Agentic Context
In **Real-World RAG**, vector stores are just the beginning. Advanced systems use **"Metadata Filtering"**. For example, your RAG system might retrieve snippets only from documents dated "2024" or only those with "High Importance". This drastically reduces "noise" in the RAG pipeline.
In **Agentic Systems**, a vector store is a **"Memory Retrieval"** tool. An agent might have access to a "Company Archive" vector store. When asked about history, it pulls the relevant historical context into its brain before responding. This is how agents maintain large-scale knowledge without exceeding their token limits.

### Did you know?
Vector search can perfectly understand the relationship between "King" and "Queen" vs "Man" and "Woman". This mathematical relationship allows the AI to "reason" across concepts that never share any identical keywords.
