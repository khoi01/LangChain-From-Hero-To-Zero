# 3.1 RAG Fundamentals (The Mental Model)

### Introduction
Retrieval Augmented Generation (RAG) is the bridge between a "clean" LLM and your "messy" real-world data. It is the architectural standard for grounding AI in facts.

### Objective
Understand the "Retrieve-Augment-Generate" flow and why it is the #1 defense against LLM hallucinations.

### Concept
RAG works like an "Open Book Exam":
1. **Retrieve:** The system looks through your library (Vector DB) for the right "page".
2. **Augment:** The "page" is pasted into the prompt as `Context`.
3. **Generate:** The LLM reads the page and answers the question.
This ensures the LLM doesn't have to "remember" factsâ€”it just has to "read" them.

### 1-Minute Implementation
Here is the entire RAG flow in a single minimalist block.

```python
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# 1. The Knowledge (Retrieve)
model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
vectorstore = Chroma.from_texts(
    ["The project ID is PX-999"], 
    embedding=HuggingFaceEmbeddings(model_name=model_name)
)
retriever = vectorstore.as_retriever()

# 2. The Instructions (Augment)
template = (
    "You must answer the question using ONLY the information provided in the context.\n"
    "Do NOT use external knowledge or make assumptions.\n"
    "If the context does not contain enough information to answer the question, reply exactly with:\n"
    "'no context'\n\n"
    "Context:\n{context}\n\n"
    "Question:\n{question}\n"
)
prompt = ChatPromptTemplate.from_template(template)

# 3. The Brain (Generate)
chain = (
    {"context": retriever, "question": RunnablePassthrough()} 
    | prompt 
    | ChatOpenAI()
)

print(chain.invoke("What is the project ID?"))
```


### Example
**Naive AI:** 
User: "What is my internal project ID?"
AI: "I think it is PX-100." (Hallucination)

**RAG AI:**
User: "What is my internal project ID?"
System: (Retrieves `project_docs.pdf`: "Project ID is PX-999")
AI: "According to your documents, the ID is PX-999." (Fact-based)

### 2 Use Cases
1. **Corporate Knowledge Bases:** Empowering employees to "chat" with thousands of pages of HR policies or technical SOPs.
2. **Financial Research:** Summarizing the latest 10-K filings for a specific company by retrieving the exact "Risk Factors" section.

### Real-World RAG & Agentic Context
In **Real-World RAG**, developers follow the **"RAG Triad"** for improvement:
1. **Context Relevance:** Did the retriever find the *right* docs?
2. **Groundedness:** Is the answer *only* based on the docs?
3. **Answer Relevance:** Does it actually answer the user?
In **Agentic Systems**, RAG is a **"Knowledge Tool"**. An agent might realize: "I don't know the answer, so I will call the `RAG_Search` tool." This turns a passive chatbot into an active researcher that can admit when it needs to look something up.

### Did you know?
RAG is much cheaper than fine-tuning a model on your data. Fine-tuning is like teaching a student everything by heart; RAG is like giving them a search engine. Most enterprise AI projects start with RAG and only fine-tune for "style" or "format" later.
