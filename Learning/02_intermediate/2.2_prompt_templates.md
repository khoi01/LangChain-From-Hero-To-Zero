# 2.2 Prompt Engineering with Templates

### Introduction
In production, prompt engineering is about **predictability and repeatability**. Instead of using fragile f-strings, LangChain's `ChatPromptTemplate` treats prompts as **structured blueprints**. This separation of logic (code) from prose (prompts) is essential for scaling AI applications.

### Core Concept: The "Blueprint"
A production-grade prompt is rarely just a single string. It is a composition of:
- **System Instructions:** Defining the AI's persona and constraints.
- **Context Placeholders:** Dynamic slots where RAG data or conversation history are injected.
- **User Query:** The specific task or question from the end user.

---

### Use Case 1: Real-World RAG (Context Grounding)
The most common use of templates in RAG is **Grounding**. You instruct the model to *only* use provided variables, which drastically reduces hallucinations.

```python
from langchain_core.prompts import ChatPromptTemplate

# Note the strict system instruction
rag_template = ChatPromptTemplate.from_messages([
    ("system", """You are a Legal Assistant. 
    Use the provided DOCUMENT CONTEXT to answer the question. 
    If the answer is not in the context, say 'I cannot find this in our database.'
    Do NOT use your own knowledge."""),
    ("user", "DOCUMENT CONTEXT:\n{context}\n\nQUESTION: {question}")
])

# Simulating a RAG retrieval step
context_data = "Section 4.2: Employees are entitled to 20 days of annual leave."
query = "How much leave do I get?"

# The template formats these into a single message list for the LLM
formatted_prompt = rag_template.invoke({
    "context": context_data,
    "question": query
})

print(formatted_prompt.to_messages())
# Resulting Output:
# [
#   SystemMessage(content="You are a Legal Assistant... (full instruction)"),
#   HumanMessage(content="DOCUMENT CONTEXT:\nSection 4.2: Employees are entitled to 20 days of annual leave.\n\nQUESTION: How much leave do I get?")
# ]
```

---

### Use Case 2: Agentic Persona Engineering
In agentic systems, templates define the "brain" of the agent.

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

agent_template = ChatPromptTemplate.from_messages([
    ("system", "You are a Research Agent."),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
    ("user", "{input}")
])

# Agents need a 'scratchpad' for their step-by-step reasoning
print(agent_template.invoke({
    "input": "Who won the World Cup 2022?",
    "agent_scratchpad": [] # Empty for first step
}).to_messages())

# Resulting Output:
# [
#   SystemMessage(content="You are a Research Agent."),
#   HumanMessage(content="Who won the World Cup 2022?")
# ]
```
> [!TIP]
> **Why do this?** By using a template, you can change the agent's behavior (e.g., making it more "creative" or "analytical") just by updating the system message, without touching your Python logic.

---

### Advanced Tool: LangChain Hub
Editing prompts inside Python files becomes messy as they grow. **LangChain Hub** (part of LangSmith) allows you to:
1. **Pull Templates:** `hub.pull("rlm/rag-prompt")` - Use community-standard prompts.
2. **Version Control:** Edit a prompt in a web UI and pull the `v2` version without redeploying code.
3. **Collaboration:** Let non-technical domain experts (like lawyers or writers) polish the prompts.

### Summary
Templates turn LLMs from "chatbots" into **reliable software components**. They are the foundation for any system that needs to process data (RAG) or perform complex tasks (Agents) consistently.
